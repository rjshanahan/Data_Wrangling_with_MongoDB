{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#LESSON 3 Example 1 - Data Audit - Chicago open street map data\n",
      "\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "import xml.etree.cElementTree as ET\n",
      "from collections import defaultdict\n",
      "import re\n",
      "\n",
      "osm_file = open(\"chicago.osm\", \"r\")\n",
      "\n",
      "street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
      "street_types = defaultdict(int)\n",
      "\n",
      "def audit_street_type(street_types, street_name):\n",
      "    m = street_type_re.search(street_name)\n",
      "    if m:\n",
      "        street_type = m.group()\n",
      "\n",
      "        street_types[street_type] += 1\n",
      "\n",
      "def print_sorted_dict(d):\n",
      "    keys = d.keys()\n",
      "    keys = sorted(keys, key=lambda s: s.lower())\n",
      "    for k in keys:\n",
      "        v = d[k]\n",
      "        print \"%s: %d\" % (k, v) \n",
      "\n",
      "def is_street_name(elem):\n",
      "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
      "\n",
      "def audit():\n",
      "    for event, elem in ET.iterparse(osm_file):\n",
      "        if is_street_name(elem):\n",
      "            audit_street_type(street_types, elem.attrib['v'])   \n",
      "    print_sorted_dict(street_types) \n",
      "\n",
      "if __name__ == '__main__':\n",
      "    audit()\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###LESSSON 3 Data Quality: version 1 - output only list of years - THIS ONE DID NOT PASS\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
      "The following things should be done:\n",
      "- check if the field \"productionStartYear\" contains a year\n",
      "- check if the year is in range 1886-2014\n",
      "- convert the value of the field to be just a year (not full datetime)\n",
      "- the rest of the fields and values should stay the same\n",
      "- if the value of the field is a valid year in range, as described above,\n",
      "  write that line to the output_good file\n",
      "- if the value of the field is not a valid year, \n",
      "  write that line to the output_bad file\n",
      "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
      "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
      "  They will take care of dealing with the header.\n",
      "\n",
      "You can write helper functions for checking the data and writing the files, but we will call only the \n",
      "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
      "\"\"\"\n",
      "import csv\n",
      "import pprint\n",
      "import xlrd\n",
      "\n",
      "INPUT_FILE = 'autos.csv'\n",
      "OUTPUT_GOOD = 'autos-valid.csv'\n",
      "OUTPUT_BAD = 'FIXME-autos.csv'\n",
      "\n",
      "def process_file(input_file, output_good, output_bad):\n",
      "    global productionStartYear_dict\n",
      "    \n",
      "    with open(INPUT_FILE, \"r\") as f1:\n",
      "        reader1 = csv.DictReader(f1)\n",
      "        #header = reader.fieldnames\n",
      "        productionStartYear_list = []\n",
      "        for row in reader1:\n",
      "            productionStartYear_list.append(row[\"productionStartYear\"])\n",
      "\n",
      "    with open(INPUT_FILE, \"r\") as f2:\n",
      "        reader2 = csv.reader(f2)\n",
      "        productionStartYear_dict = {}\n",
      "        for line in reader2:\n",
      "            productionStartYear_dict[line[0]] = line[33]\n",
      "\n",
      "    with open(output_good, \"w\") as f3:\n",
      "        good = csv.writer(f3, lineterminator='\\n', quotechar='\"')\n",
      "        for row in productionStartYear_dict.itervalues():\n",
      "            try:\n",
      "                if int(row[0:4]) >= 1886 and int(row[0:4]) <= 2014:\n",
      "                    good.writerow([int(row[0:4])])\n",
      "                #elif row.startswith('http://dbpedia.org'):\n",
      "                #    pass\n",
      "            except ValueError:\n",
      "                pass\n",
      "           \n",
      "            \n",
      "    with open(output_bad, \"w\") as f4:\n",
      "        bad = csv.writer(f4,  lineterminator = '\\n', quotechar='\"')\n",
      "        for row in productionStartYear_dict.iteritems():\n",
      "            try:\n",
      "                #if int(row[0:4]) and int(row[0:4]) >= 1886 and int(row[0:4]) <= 2014 and not row.startswith('http://dbpedia.org'):\n",
      "                if row[0].startswith('http://dbpedia.org'):\n",
      "                    pass\n",
      "                elif int(row[1]) <= 1886 or int(row[1]) >= 2014:\n",
      "                    #good.writerow([int(row[0:4])])\n",
      "                #elif row.startswith('http://dbpedia.org'):\n",
      "                    pass\n",
      "            except ValueError:\n",
      "                bad.writerow([row])\n",
      "                pass\n",
      "\n",
      "\n",
      "def test():\n",
      "\n",
      "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###LESSSON 3 Data Quality - version 2: write ALL fields + update year field in integer - THIS ONE PASSES\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
      "The following things should be done:\n",
      "- check if the field \"productionStartYear\" contains a year\n",
      "- check if the year is in range 1886-2014\n",
      "- convert the value of the field to be just a year (not full datetime)\n",
      "- the rest of the fields and values should stay the same\n",
      "- if the value of the field is a valid year in range, as described above,\n",
      "  write that line to the output_good file\n",
      "- if the value of the field is not a valid year, \n",
      "  write that line to the output_bad file\n",
      "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
      "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
      "  They will take care of dealing with the header.\n",
      "\n",
      "You can write helper functions for checking the data and writing the files, but we will call only the \n",
      "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
      "\"\"\"\n",
      "import csv\n",
      "import pprint\n",
      "import xlrd\n",
      "\n",
      "INPUT_FILE = 'autos.csv'\n",
      "OUTPUT_GOOD = 'autos-valid.csv'\n",
      "OUTPUT_BAD = 'FIXME-autos.csv'\n",
      "\n",
      "def filewriter(dictionarylist, outputfile):\n",
      "    global header\n",
      "    with open(outputfile, 'w') as f:\n",
      "        writer = csv.DictWriter(f, delimiter=',', fieldnames=header)\n",
      "        writer.writeheader()\n",
      "        writer.writerows(dictionarylist)\n",
      "        f.close()\n",
      "\n",
      "def process_file(input_file, output_good, output_bad):\n",
      "    global header\n",
      "    \n",
      "    goodlist = []\n",
      "    badlist = []\n",
      "        \n",
      "    with open(input_file, \"r\") as f:\n",
      "        reader = csv.DictReader(f)\n",
      "        header = reader.fieldnames\n",
      "        #productionStartYear_list = []\n",
      "        for row in reader:\n",
      "            \n",
      "            datetime = str(row['productionStartYear'])[:4]\n",
      "            try:\n",
      "                datetime = int(datetime)\n",
      "            #if it works, change the production start year value in row k\n",
      "                if isinstance(datetime, (int, long)):\n",
      "                    row['productionStartYear'] = int(datetime)\n",
      "            except ValueError:\n",
      "                pass\n",
      "\n",
      "        #check if URI contains dbpedia.org\n",
      "            if 'dbpedia.org' not in row['URI']:\n",
      "            #if it's not, return to top of for loop\n",
      "                continue\n",
      "            elif type(datetime) is int and datetime >= 1886 and datetime <= 2014:\n",
      "                goodlist += [row]\n",
      "  \n",
      "            #if that condition is satisfied AND it's a valid year add that row to the good list (of dictionaries)\n",
      "            else:\n",
      "                badlist += [row]\n",
      "\n",
      "#convert the lists of dictionaries into csv files\n",
      "        filewriter(goodlist,output_good)\n",
      "        filewriter(badlist,output_bad)\n",
      "\n",
      "\n",
      "#two new functions to write rows\n",
      "#change to write entire file\n",
      "            \n",
      "def test():\n",
      "\n",
      "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### LESSON 3: Problem Set Q1\n",
      "\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "In this problem set you work with cities infobox data, audit it, come up with a cleaning idea and then\n",
      "clean it up. In the first exercise we want you to audit the datatypes that can be found in some \n",
      "particular fields in the dataset.\n",
      "The possible types of values can be:\n",
      "- 'NoneType' if the value is a string \"NULL\" or an empty string \"\"\n",
      "- 'list', if the value starts with \"{\"\n",
      "- 'int', if the value can be cast to int\n",
      "- 'float', if the value can be cast to float, but is not an int\n",
      "- 'str', for all other values\n",
      "\n",
      "The audit_file function should return a dictionary containing fieldnames and a set of the datatypes\n",
      "that can be found in the field.\n",
      "All the data initially is a string, so you have to do some checks on the values first.\n",
      "\n",
      "\"\"\"\n",
      "import codecs\n",
      "import csv\n",
      "import json\n",
      "import pprint\n",
      "\n",
      "CITIES = 'cities.csv'\n",
      "\n",
      "FIELDS = [\"name\", \"timeZone_label\", \"utcOffset\", \"homepage\", \"governmentType_label\", \"isPartOf_label\", \"areaCode\", \"populationTotal\", \n",
      "          \"elevation\", \"maximumElevation\", \"minimumElevation\", \"populationDensity\", \"wgs84_pos#lat\", \"wgs84_pos#long\", \n",
      "          \"areaLand\", \"areaMetro\", \"areaUrban\"]\n",
      "\n",
      "def audit_file(filename, fields):\n",
      "    fieldtypes = {}\n",
      "\n",
      "    # YOUR CODE HERE\n",
      "    for fld in fields:\n",
      "        fieldtypes[fld] = set()\n",
      "        with open(filename, \"r\") as f:\n",
      "           \n",
      "            reader = csv.DictReader(f)\n",
      "            #skip first 3 lines\n",
      "            next(reader)\n",
      "            next(reader)\n",
      "            next(reader)\n",
      "            \n",
      "            for line in reader:\n",
      "                \n",
      "                if line[fld]== \"NULL\" or line[fld] == \"\":\n",
      "                    fieldtypes[fld].add(type(None))\n",
      "                elif line[fld].startswith(\"{\"):\n",
      "                    fieldtypes[fld].add(type([]))\n",
      "                elif numcheck(line[fld]):\n",
      "                    if float(line[fld]).is_integer():\n",
      "                        fieldtypes[fld].add(type(1.1))\n",
      "                    else:\n",
      "                        fieldtypes[fld].add(type(1))\n",
      "                else:\n",
      "                    fieldtypes[fld].add(type(\"string\"))\n",
      "\n",
      "    return fieldtypes\n",
      "\n",
      "\n",
      "def numcheck(value): \n",
      "    try:\n",
      "        float(value)\n",
      "        return True\n",
      "    except ValueError:\n",
      "        return False\n",
      "\n",
      "\n",
      "def test():\n",
      "    fieldtypes = audit_file(CITIES, FIELDS)\n",
      "\n",
      "    pprint.pprint(fieldtypes)\n",
      "\n",
      "    assert fieldtypes[\"areaLand\"] == set([type(1.1), type([]), type(None)])\n",
      "    assert fieldtypes['areaMetro'] == set([type(1.1), type(None)])\n",
      "    \n",
      "if __name__ == \"__main__\":\n",
      "    test()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'areaCode': set([<type 'float'>, <type 'NoneType'>, <type 'str'>]),\n",
        " 'areaLand': set([<type 'float'>, <type 'list'>, <type 'NoneType'>]),\n",
        " 'areaMetro': set([<type 'float'>, <type 'NoneType'>]),\n",
        " 'areaUrban': set([<type 'float'>, <type 'NoneType'>]),\n",
        " 'elevation': set([<type 'float'>, <type 'list'>, <type 'NoneType'>]),\n",
        " 'governmentType_label': set([<type 'NoneType'>, <type 'str'>]),\n",
        " 'homepage': set([<type 'NoneType'>, <type 'str'>]),\n",
        " 'isPartOf_label': set([<type 'list'>, <type 'NoneType'>, <type 'str'>]),\n",
        " 'maximumElevation': set([<type 'NoneType'>]),\n",
        " 'minimumElevation': set([<type 'NoneType'>]),\n",
        " 'name': set([<type 'list'>, <type 'NoneType'>, <type 'str'>]),\n",
        " 'populationDensity': set([<type 'int'>, <type 'list'>, <type 'NoneType'>]),\n",
        " 'populationTotal': set([<type 'float'>, <type 'NoneType'>]),\n",
        " 'timeZone_label': set([<type 'NoneType'>, <type 'str'>]),\n",
        " 'utcOffset': set([<type 'float'>,\n",
        "                   <type 'list'>,\n",
        "                   <type 'NoneType'>,\n",
        "                   <type 'str'>]),\n",
        " 'wgs84_pos#lat': set([<type 'int'>]),\n",
        " 'wgs84_pos#long': set([<type 'int'>])}\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### LESSON 3: Problem Set Q3 - FAILS ASSERTION FOR SOME FUCKING REASON\n",
      "\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "In this problem set you work with cities infobox data, audit it, come up with a cleaning idea and then clean it up.\n",
      "\n",
      "Since in the previous quiz you made a decision on which value to keep for the \"areaLand\" field,\n",
      "you now know what has to be done.\n",
      "\n",
      "Finish the function fix_area(). It will receive a string as an input, and it has to return a float\n",
      "representing the value of the area or None.\n",
      "You have to change the function fix_area. You can use extra functions if you like, but changes to process_file\n",
      "will not be taken into account.\n",
      "The rest of the code is just an example on how this function can be used.\n",
      "\"\"\"\n",
      "import codecs\n",
      "import csv\n",
      "import json\n",
      "import pprint\n",
      "import re\n",
      "\n",
      "CITIES = 'cities.csv'\n",
      "\n",
      "\n",
      "def fix_area(area):\n",
      "    global mydata\n",
      "    # YOUR CODE HERE\n",
      "    \n",
      "    pattern = re.compile(r\"\\{|\\}|\\|\")\n",
      "    mydata = []\n",
      "    try:\n",
      "    \n",
      "        if '|' in str(area):\n",
      "            #al = pattern.split(area)\n",
      "            #if len(str(float((pattern.split(area))[1])))-1 > len(str(float((pattern.split(area))[2])))-1:\n",
      "            if len((pattern.split(area))[1]) > len((pattern.split(area))[2]):\n",
      "                print float((pattern.split(area))[1])\n",
      "            else:\n",
      "                print float((pattern.split(area))[2])\n",
      "        elif area == \"NULL\" or area == \"\":\n",
      "            print None\n",
      "        else:\n",
      "            print float(area)\n",
      "            \n",
      "    except TypeError: \n",
      "    \n",
      "        if area == \"NULL\" or area == \"\":\n",
      "            print None\n",
      "        else:\n",
      "            print float(area)\n",
      "\n",
      "\n",
      "    return area\n",
      "\n",
      "\n",
      "\n",
      "def process_file(filename):\n",
      "    # CHANGES TO THIS FUNCTION WILL BE IGNORED WHEN YOU SUBMIT THE EXERCISE\n",
      "    data = []\n",
      "\n",
      "    with open(filename, \"r\") as f:\n",
      "        reader = csv.DictReader(f)\n",
      "\n",
      "        #skipping the extra matadata\n",
      "        for i in range(3):\n",
      "            l = reader.next()\n",
      "\n",
      "        # processing file\n",
      "        for line in reader:\n",
      "            # calling your function to fix the area value\n",
      "            if \"areaLand\" in line:\n",
      "                line[\"areaLand\"] = fix_area(line[\"areaLand\"])\n",
      "            data.append(line)\n",
      "\n",
      "    return data\n",
      "\n",
      "\n",
      "def test():\n",
      "    data = process_file(CITIES)\n",
      "\n",
      "    print \"Printing three example results:\"\n",
      "    for n in range(5,8):\n",
      "        pprint.pprint(data[n][\"areaLand\"])\n",
      "\n",
      "    assert data[8][\"areaLand\"] == 55166700.0\n",
      "    assert data[3][\"areaLand\"] == None\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-96-9aa084205825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-96-9aa084205825>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"areaLand\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"areaLand\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m55166700.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"areaLand\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAssertionError\u001b[0m: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "None\n",
        "None\n",
        "None\n",
        "None\n",
        "None\n",
        "101787000.0\n",
        "31597900.0\n",
        "55166700.0\n",
        "63713700.0\n",
        "37813800.0\n",
        "20201900.0\n",
        "287489000.0\n",
        "25356000.0\n",
        "251229000.0\n",
        "82620600.0\n",
        "35819500.0\n",
        "11300000.0\n",
        "53200000.0\n",
        "4480680.0\n",
        "14581600.0\n",
        "17119800.0\n",
        "2071990.0\n",
        "4610180.0\n",
        "3263390.0\n",
        "90571900.0\n",
        "12742700.0\n",
        "31364800.0\n",
        "53146600.0\n",
        "34317300.0\n",
        "5335380.0\n",
        "81843600.0\n",
        "11395900.0\n",
        "20564500.0\n",
        "97823900.0\n",
        "None\n",
        "None\n",
        "4946880.0\n",
        "12017500.0\n",
        "Printing three example results:\n",
        "'NULL'\n",
        "'{1.01787e+08|1.019e+08}'\n",
        "'{3.15979e+07|3.17e+07}'\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### LESSON 3: Problem Set Q3 - PASSES\n",
      "\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "In this problem set you work with cities infobox data, audit it, come up with a cleaning idea and then clean it up.\n",
      "\n",
      "Since in the previous quiz you made a decision on which value to keep for the \"areaLand\" field,\n",
      "you now know what has to be done.\n",
      "\n",
      "Finish the function fix_area(). It will receive a string as an input, and it has to return a float\n",
      "representing the value of the area or None.\n",
      "You have to change the function fix_area. You can use extra functions if you like, but changes to process_file\n",
      "will not be taken into account.\n",
      "The rest of the code is just an example on how this function can be used.\n",
      "\"\"\"\n",
      "import codecs\n",
      "import csv\n",
      "import json\n",
      "import pprint\n",
      "import re\n",
      "\n",
      "CITIES = 'cities.csv'\n",
      "\n",
      "\n",
      "def fix_area(area):\n",
      "    global mydata\n",
      "    # YOUR CODE HERE\n",
      "    \n",
      "    if area == 'NULL':\n",
      "        area = None\n",
      "    else:\n",
      "        if area.startswith('{'):\n",
      "            area_1 = area.split('|')[0][1:]\n",
      "            area_2 = area.split('|')[1][:-1]\n",
      "            if len(area_1) > len(area_2):\n",
      "                area = float(area_1)\n",
      "            else:\n",
      "                area = float(area_2)\n",
      "        else: \n",
      "            area = float(area)\n",
      "\n",
      "\n",
      "    return area\n",
      "\n",
      "\n",
      "\n",
      "def process_file(filename):\n",
      "    # CHANGES TO THIS FUNCTION WILL BE IGNORED WHEN YOU SUBMIT THE EXERCISE\n",
      "    data = []\n",
      "\n",
      "    with open(filename, \"r\") as f:\n",
      "        reader = csv.DictReader(f)\n",
      "\n",
      "        #skipping the extra matadata\n",
      "        for i in range(3):\n",
      "            l = reader.next()\n",
      "\n",
      "        # processing file\n",
      "        for line in reader:\n",
      "            # calling your function to fix the area value\n",
      "            if \"areaLand\" in line:\n",
      "                line[\"areaLand\"] = fix_area(line[\"areaLand\"])\n",
      "            data.append(line)\n",
      "\n",
      "    return data\n",
      "\n",
      "\n",
      "def test():\n",
      "    data = process_file(CITIES)\n",
      "\n",
      "    print \"Printing three example results:\"\n",
      "    for n in range(5,8):\n",
      "        pprint.pprint(data[n][\"areaLand\"])\n",
      "\n",
      "    assert data[8][\"areaLand\"] == 55166700.0\n",
      "    assert data[3][\"areaLand\"] == None\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Printing three example results:\n",
        "None\n",
        "101787000.0\n",
        "31597900.0\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### LESSON 3 Problem Set Q5 - PASSES\n",
      "\n",
      "\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "In this problem set you work with cities infobox data, audit it, come up with a cleaning idea and then clean it up.\n",
      "\n",
      "In the previous quiz you recognized that the \"name\" value can be an array (or list in Python terms).\n",
      "It would make it easier to process and query the data later, if all values for the name \n",
      "would be in a Python list, instead of being just a string separated with special characters, like now.\n",
      "\n",
      "Finish the function fix_name(). It will recieve a string as an input, and it has to return a list\n",
      "of all the names. If there is only one name, the list with have only one item in it, if the name is \"NULL\",\n",
      "the list should be empty.\n",
      "The rest of the code is just an example on how this function can be used\n",
      "\"\"\"\n",
      "import codecs\n",
      "import csv\n",
      "import pprint\n",
      "import re\n",
      "\n",
      "CITIES = 'cities.csv'\n",
      "\n",
      "def fix_name(name):\n",
      "\n",
      "    # YOUR CODE HERE\n",
      "    \n",
      "    pattern = re.compile(r\"\\{|\\||\\}\")\n",
      "    \n",
      "    if name == 'NULL' or name == \"\":\n",
      "        name = []\n",
      "    else:\n",
      "        if name.startswith('{'):\n",
      "            name = [((pattern.split(name))[1]), ((pattern.split(name))[2])]\n",
      "        else:\n",
      "            name = [name]\n",
      "\n",
      "\n",
      "    return name\n",
      "\n",
      "\n",
      "def process_file(filename):\n",
      "    global data\n",
      "    data = []\n",
      "    with open(filename, \"r\") as f:\n",
      "        reader = csv.DictReader(f)\n",
      "        #skipping the extra matadata\n",
      "        for i in range(3):\n",
      "            i = reader.next()\n",
      "        # processing file\n",
      "        for line in reader:\n",
      "            # calling your function to fix the area value\n",
      "            if \"name\" in line:\n",
      "                line[\"name\"] = fix_name(line[\"name\"])\n",
      "            data.append(line)\n",
      "    return data\n",
      "\n",
      "\n",
      "def test():\n",
      "    data = process_file(CITIES)\n",
      "\n",
      "    print \"Printing 20 results:\"\n",
      "    for n in range(20):\n",
      "        pprint.pprint(data[n][\"name\"])\n",
      "\n",
      "    assert data[14][\"name\"] == ['Negtemiut', 'Nightmute']\n",
      "    assert data[3][\"name\"] == ['Kumhari']\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Printing 20 results:\n",
        "['Kud']\n",
        "['Kuju']\n",
        "['Kumbhraj']\n",
        "['Kumhari']\n",
        "['Kunigal']\n",
        "['Kurgunta']\n",
        "['Athens']\n",
        "['Demopolis']\n",
        "['Chelsea Alabama']\n",
        "['Pell City Alabama']\n",
        "['City of Northport']\n",
        "['Sand Point']\n",
        "['Unalaska Alaska']\n",
        "['City of Menlo Park']\n",
        "['Negtemiut', 'Nightmute']\n",
        "['Fairbanks Alaska']\n",
        "['Homer']\n",
        "['Ketchikan Alaska']\n",
        "['Nuniaq', 'Old Harbor']\n",
        "['Rainier Washington']\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### LESSON 3 Problem Set Q 6 - PASSES\n",
      "\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "In this problem set you work with cities infobox data, audit it, come up with a cleaning idea and then clean it up.\n",
      "\n",
      "If you look at the full city data, you will notice that there are couple of values that seem to provide\n",
      "the same information in different formats: \"point\" seems to be the combination of \"wgs84_pos#lat\" and \"wgs84_pos#long\".\n",
      "However we do not know if that is the case and should check if they are equivalent.\n",
      "\n",
      "Finish the function check_loc(). It will recieve 3 strings, first will be the combined value of \"point\" and then the\n",
      "\"wgs84_pos#\" values separately. You have to extract the lat and long values from the \"point\" and compare\n",
      "to the \"wgs84_pos# values and return True or False.\n",
      "\n",
      "Note that you do not have to fix the values, just determine if they are consistent. To fix them in this case\n",
      "you would need more information. Feel free to discuss possible strategies for fixing this on the discussion forum.\n",
      "\n",
      "The rest of the code is just an example on how this function can be used.\n",
      "Changes to \"process_file\" function will not be take into account.\n",
      "\"\"\"\n",
      "import csv\n",
      "import pprint\n",
      "import re\n",
      "\n",
      "CITIES = 'cities.csv'\n",
      "\n",
      "\n",
      "def check_loc(point, lat, longi):\n",
      "    # YOUR CODE HERE\n",
      "    \n",
      "    if point.split()[0] == lat and point.split()[1] == longi:\n",
      "        return True\n",
      "    else:\n",
      "        return False    \n",
      "    \n",
      "    \n",
      "    pass\n",
      "\n",
      "\n",
      "def process_file(filename):\n",
      "    data = []\n",
      "    with open(filename, \"r\") as f:\n",
      "        reader = csv.DictReader(f)\n",
      "        #skipping the extra matadata\n",
      "        for i in range(3):\n",
      "            l = reader.next()\n",
      "        # processing file\n",
      "        for line in reader:\n",
      "            # calling your function to check the location\n",
      "            result = check_loc(line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])\n",
      "            if not result:\n",
      "                print \"{}: {} != {} {}\".format(line[\"name\"], line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])\n",
      "            data.append(line)\n",
      "\n",
      "    return data\n",
      "\n",
      "\n",
      "def test():\n",
      "    assert check_loc(\"33.08 75.28\", \"33.08\", \"75.28\") == True\n",
      "    assert check_loc(\"44.57833333333333 -91.21833333333333\", \"44.5783\", \"-91.2183\") == False\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    test()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    }
   ],
   "metadata": {}
  }
 ]
}
